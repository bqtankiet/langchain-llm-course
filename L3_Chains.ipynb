{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "52824b89-532a-4e54-87e9-1410813cd39e",
      "metadata": {
        "id": "52824b89-532a-4e54-87e9-1410813cd39e"
      },
      "source": [
        "# Lesson 3: Chains\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/bqtankiet/langchain-llm-course/blob/main/L3_Chains.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "This notebook documents my learning journey on **LangChain for LLM Application Development** course from Deeplearning.ai \\\n",
        "[Lesson 3: Chains](https://learn.deeplearning.ai/courses/langchain/lesson/glsn3/chains)\n",
        "\n",
        "\\\n",
        "What I Learned\n",
        "- How to create a simple chain with LangChain Expression Language (LCEL) using the | (pipe) operator.\n",
        "- How to build a Sequential Chain where the output of one component becomes the input of the next.\n",
        "- How to execute chains in parallel using `RunnableParallel` to create a Parallel Chain.\n",
        "- How to implement a Router Chain with `RunnableBranch` to dynamically route inputs to different chains based on the input.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "D89WYZKt3xeJ",
      "metadata": {
        "id": "D89WYZKt3xeJ"
      },
      "source": [
        "## Setting up the Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25yD7-nk31CM",
      "metadata": {
        "id": "25yD7-nk31CM"
      },
      "outputs": [],
      "source": [
        "!pip install -qU python-dotenv\n",
        "!pip install -qU langchain-groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
      "metadata": {
        "height": 96,
        "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "_ = load_dotenv() # read local .env file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4336d784-65c2-4a11-8489-b445b1fad177",
      "metadata": {
        "height": 249,
        "id": "4336d784-65c2-4a11-8489-b445b1fad177"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "llm = init_chat_model(\n",
        "    model = \"llama-3.3-70b-versatile\",\n",
        "    model_provider = \"groq\",\n",
        "    temperature = 0.9\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "974acf8e-8f88-42de-88f8-40a82cb58e8b",
      "metadata": {
        "height": 47,
        "id": "974acf8e-8f88-42de-88f8-40a82cb58e8b",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7a09c35",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "height": 30,
        "id": "b7a09c35",
        "outputId": "6cc878b4-beda-4013-911b-857e44ab8e1b",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Product\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Waterproof Phone Pouch\",\n          \"L'Or Espresso Caf\\u00e9\",\n          \"Queen Size Sheet Set\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"I loved the waterproof sac, although the opening was made of a hard plastic. I don\\u2019t know if that would break easily. But I couldn\\u2019t turn my phone on, once it was in the pouch.\",\n          \"Je trouve le go\\u00fbt m\\u00e9diocre. La mousse ne tient pas, c'est bizarre. J'ach\\u00e8te les m\\u00eames dans le commerce et le go\\u00fbt est bien meilleur... Vieux lot ou contrefa\\u00e7on !?\",\n          \"I ordered a king size set. My only criticism would be that I wish seller would offer the king size set with 4 pillowcases. I separately ordered a two pack of pillowcases so I could have a total of four. When I saw the two packages, it looked like the color did not exactly match. Customer service was excellent about sending me two more pillowcases so I would have four that matched. Excellent! For the cost of these sheets, I am satisfied with the characteristics and coolness of the sheets.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-5a47444a-64e9-486d-9919-7ef99e5e4b3f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Product</th>\n",
              "      <th>Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Queen Size Sheet Set</td>\n",
              "      <td>I ordered a king size set. My only criticism w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Waterproof Phone Pouch</td>\n",
              "      <td>I loved the waterproof sac, although the openi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Luxury Air Mattress</td>\n",
              "      <td>This mattress had a small hole in the top of i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Pillows Insert</td>\n",
              "      <td>This is the best throw pillow fillers on Amazo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Milk Frother Handheld</td>\n",
              "      <td>I loved this product. But they only seem to l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>L'Or Espresso Café</td>\n",
              "      <td>Je trouve le goût médiocre. La mousse ne tient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Hervidor de Agua Eléctrico</td>\n",
              "      <td>Está lu bonita calienta muy rápido, es muy fun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Bánh kem ABC</td>\n",
              "      <td>Hương vị quá tệ! Lớp kem thì chảy nước. Chắc c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a47444a-64e9-486d-9919-7ef99e5e4b3f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5a47444a-64e9-486d-9919-7ef99e5e4b3f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5a47444a-64e9-486d-9919-7ef99e5e4b3f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-944460bc-edfc-445d-848b-3f413f3b1cf0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-944460bc-edfc-445d-848b-3f413f3b1cf0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-944460bc-edfc-445d-848b-3f413f3b1cf0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_fc1b47a3-fd08-421b-905a-a0404cc8033e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_fc1b47a3-fd08-421b-905a-a0404cc8033e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                      Product  \\\n",
              "0        Queen Size Sheet Set   \n",
              "1      Waterproof Phone Pouch   \n",
              "2         Luxury Air Mattress   \n",
              "3              Pillows Insert   \n",
              "4       Milk Frother Handheld   \n",
              "5          L'Or Espresso Café   \n",
              "6  Hervidor de Agua Eléctrico   \n",
              "7                Bánh kem ABC   \n",
              "\n",
              "                                              Review  \n",
              "0  I ordered a king size set. My only criticism w...  \n",
              "1  I loved the waterproof sac, although the openi...  \n",
              "2  This mattress had a small hole in the top of i...  \n",
              "3  This is the best throw pillow fillers on Amazo...  \n",
              "4   I loved this product. But they only seem to l...  \n",
              "5  Je trouve le goût médiocre. La mousse ne tient...  \n",
              "6  Está lu bonita calienta muy rápido, es muy fun...  \n",
              "7  Hương vị quá tệ! Lớp kem thì chảy nước. Chắc c...  "
            ]
          },
          "execution_count": 271,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b940ce7c",
      "metadata": {
        "id": "b940ce7c"
      },
      "source": [
        "## I. LangChain Expression Language\n",
        "Build a simple LCEL chain: prompt | model | output parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e92dff22",
      "metadata": {
        "height": 64,
        "id": "e92dff22",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers.string import StrOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdcdb42d",
      "metadata": {
        "height": 81,
        "id": "cdcdb42d",
        "tags": []
      },
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"What is the best name to describe \\\n",
        "    a company that makes {product}?. \\\n",
        "    Respond only one company name\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rmbGpdsKAOU0",
      "metadata": {
        "id": "rmbGpdsKAOU0"
      },
      "outputs": [],
      "source": [
        "parser = StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7abc20b",
      "metadata": {
        "height": 30,
        "id": "d7abc20b",
        "tags": []
      },
      "outputs": [],
      "source": [
        "chain = prompt | llm | parser # LCEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dYo6lvDD65a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYo6lvDD65a7",
        "outputId": "58cbcc63-4189-47ca-a255-e400df45c6d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
          ]
        }
      ],
      "source": [
        "# just see what type it is\n",
        "print(type(chain))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad44d1fb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "height": 47,
        "id": "ad44d1fb",
        "outputId": "55657dd3-4705-4728-c92c-171d475f87e2",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'RoyalSlumber'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "product = \"Queen Size Sheet Set\"\n",
        "chain.invoke({\"product\": product})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69b03469",
      "metadata": {
        "id": "69b03469"
      },
      "source": [
        "## II. Sequential Chain\n",
        "Build a two-step chain: generate a company name → write a short company description \\\n",
        "(step 2 depends on step 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f31aa8a",
      "metadata": {
        "height": 183,
        "id": "2f31aa8a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# prompt template 1\n",
        "first_prompt = ChatPromptTemplate.from_template(\n",
        "    \"What is the best name to describe \\\n",
        "    a company that makes {product}?\"\n",
        ")\n",
        "\n",
        "chain_1 = first_prompt | llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ZfNMdspEhj1",
      "metadata": {
        "id": "0ZfNMdspEhj1"
      },
      "outputs": [],
      "source": [
        "# prompt template 2\n",
        "second_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Write a 20 words description for the following \\\n",
        "    company:{company_name}\"\n",
        ")\n",
        "\n",
        "chain_2 = second_prompt | llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c1eb2c4",
      "metadata": {
        "height": 79,
        "id": "6c1eb2c4",
        "tags": []
      },
      "outputs": [],
      "source": [
        "overall_chain = (\n",
        "    {\"company_name\": chain_1}\n",
        "    | chain_2\n",
        "    | parser\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78458efe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "height": 30,
        "id": "78458efe",
        "outputId": "119b122a-04ae-43db-ee73-18af9d086313",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Luxurious bedding company offering high-quality queen size sheet sets for optimal comfort and restful sleep experiences always.'"
            ]
          },
          "execution_count": 278,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "overall_chain.invoke({\"product\": product})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b5ce18c",
      "metadata": {
        "id": "7b5ce18c"
      },
      "source": [
        "## III. Parallel Chain"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sbttegtN1oBF",
      "metadata": {
        "id": "sbttegtN1oBF"
      },
      "source": [
        "Set up the prompt templates used to:\n",
        "1. Translate the review\n",
        "\n",
        "2. Detect the language\n",
        "\n",
        "3. Summarize the review\n",
        "\n",
        "4. Generate a follow-up response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "016187ac",
      "metadata": {
        "height": 232,
        "id": "016187ac",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# prompt template 1: Translate the review\n",
        "prompt_1 = ChatPromptTemplate.from_template(\n",
        "    \"Translate the following review to English, \"\n",
        "    \"just respond the translated review:\"\n",
        "    \"\\n\\n{review}\"\n",
        ")\n",
        "chain_translate = prompt_1 | llm | parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6accf92d",
      "metadata": {
        "height": 181,
        "id": "6accf92d",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# prompt template 2: Detect the language\n",
        "prompt_2 = ChatPromptTemplate.from_template(\n",
        "    \"What language is the following review, \"\n",
        "    \"just respond the language:\"\n",
        "    \"\\n\\n{review}\"\n",
        ")\n",
        "chain_language = prompt_2 | llm | parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fb0730e",
      "metadata": {
        "height": 181,
        "id": "0fb0730e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# prompte template 3: Summarize the review\n",
        "prompt_3 = ChatPromptTemplate.from_template(\n",
        "    \"Summarize the following review in 1 sentence, \"\n",
        "    \"just respond the summarized sentence:\"\n",
        "    \"\\n\\n{english_review}\"\n",
        ")\n",
        "chain_summary = prompt_3 | llm | parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7a46121",
      "metadata": {
        "height": 232,
        "id": "c7a46121",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# prompt template 4: Generate a follow-up response\n",
        "prompt_4 = ChatPromptTemplate.from_template(\n",
        "    \"With the given summary of the customer review, \"\n",
        "    \"write a follow-up response in the specified language. \"\n",
        "    \"Just return the response sentence\"\n",
        "    \"\\n\\nSummary: {summary}\\n\\nLanguage: {language}\"\n",
        ")\n",
        "chain_followup = prompt_4 | llm | parser"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BKp2PRnq1v1R",
      "metadata": {
        "id": "BKp2PRnq1v1R"
      },
      "source": [
        "Full pipeline: translate, detect language, summarize, and respond"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JsOU8x3wuS9h",
      "metadata": {
        "id": "JsOU8x3wuS9h"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnableParallel\n",
        "from operator import itemgetter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "C7uiWwEUig4E",
      "metadata": {
        "id": "C7uiWwEUig4E"
      },
      "outputs": [],
      "source": [
        "# approach_1: keep all results from each step\n",
        "approach_1 = (\n",
        "  RunnableParallel(\n",
        "    english_review=chain_translate,\n",
        "    language=chain_language,\n",
        "  ).assign(\n",
        "      summary=chain_summary\n",
        "  ).assign(\n",
        "      followup_message=chain_followup\n",
        "  )\n",
        ") # The output is a dict containing all step results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bE6wzBl0uUXh",
      "metadata": {
        "id": "bE6wzBl0uUXh"
      },
      "outputs": [],
      "source": [
        "# approach_2: only pass needed results to the next step\n",
        "approach_2 = (\n",
        "    RunnableParallel(\n",
        "      english_review=chain_translate,\n",
        "      language=chain_language,\n",
        "    )\n",
        "    | {\n",
        "        \"summary\": chain_summary,\n",
        "        \"language\": itemgetter(\"language\")\n",
        "    }\n",
        "    | chain_followup\n",
        ") # Only keep the final output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WBN7gZqT2316",
      "metadata": {
        "id": "WBN7gZqT2316"
      },
      "source": [
        "Run both approaches on a sample review"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EbvbpiWgwGoK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EbvbpiWgwGoK",
        "outputId": "0d4a6432-b3ed-46cc-f645-4ced636ddb30"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Hương vị quá tệ! Lớp kem thì chảy nước. Chắc chắn là hàng kém chất lượng hoặc bị để lâu rồi!'"
            ]
          },
          "execution_count": 272,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "review = df.Review[7]\n",
        "review"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vhvDuWd5leQs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhvDuWd5leQs",
        "outputId": "c9e9937e-2c24-44ef-cdba-824d2a704f75"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'english_review': \"The taste is terrible! The cream layer is watery. It's definitely low-quality goods or has been left out for too long!\",\n",
              " 'language': 'Vietnamese',\n",
              " 'summary': 'The reviewer strongly dislikes the product, citing a terrible taste, watery cream layer, and suspecting it may be low-quality or spoiled.',\n",
              " 'followup_message': 'Xin lỗi vì sản phẩm của chúng tôi không đáp ứng được nhu cầu và mong đợi của quý khách, chúng tôi sẽ xem xét lại chất lượng và quy trình sản xuất để cải thiện sản phẩm trong tương lai.'}"
            ]
          },
          "execution_count": 273,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "approach_1.invoke(review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DFd0nH8olhbl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "DFd0nH8olhbl",
        "outputId": "843bc1dc-c727-4375-ff55-97ef21e776d1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Xin lỗi vì sản phẩm không đáp ứng được kỳ vọng của quý khách, chúng tôi sẽ xem xét lại chất lượng và quy trình bảo quản để cải thiện sản phẩm trong tương lai.'"
            ]
          },
          "execution_count": 274,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "approach_2.invoke(review)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3041ea4c",
      "metadata": {
        "id": "3041ea4c"
      },
      "source": [
        "## IV. Router Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ade83f4f",
      "metadata": {
        "height": 793,
        "id": "ade83f4f",
        "tags": []
      },
      "outputs": [],
      "source": [
        "physics_template = \"\"\"You are a very smart physics professor. \\\n",
        "You are great at answering questions about physics in a concise\\\n",
        "and easy to understand manner. \\\n",
        "When you don't know the answer to a question you admit\\\n",
        "that you don't know.\n",
        "\n",
        "Here is a question:\n",
        "{question}\"\"\"\n",
        "\n",
        "math_template = \"\"\"You are a very good mathematician. \\\n",
        "You are great at answering math questions. \\\n",
        "You are so good because you are able to break down \\\n",
        "hard problems into their component parts,\n",
        "answer the component parts, and then put them together\\\n",
        "to answer the broader question.\n",
        "\n",
        "Here is a question:\n",
        "{question}\"\"\"\n",
        "\n",
        "history_template = \"\"\"You are a very good historian. \\\n",
        "You have an excellent knowledge of and understanding of people,\\\n",
        "events and contexts from a range of historical periods. \\\n",
        "You have the ability to think, reflect, debate, discuss and \\\n",
        "evaluate the past. You have a respect for historical evidence\\\n",
        "and the ability to make use of it to support your explanations \\\n",
        "and judgements.\n",
        "\n",
        "Here is a question:\n",
        "{question}\"\"\"\n",
        "\n",
        "computerscience_template = \"\"\" You are a successful computer scientist.\\\n",
        "You have a passion for creativity, collaboration,\\\n",
        "forward-thinking, confidence, strong problem-solving capabilities,\\\n",
        "understanding of theories and algorithms, and excellent communication \\\n",
        "skills. You are great at answering coding questions. \\\n",
        "You are so good because you know how to solve a problem by \\\n",
        "describing the solution in imperative steps \\\n",
        "that a machine can easily interpret and you know how to \\\n",
        "choose a solution that has a good balance between \\\n",
        "time complexity and space complexity.\n",
        "\n",
        "Here is a question:\n",
        "{question}\"\"\"\n",
        "\n",
        "default_template = \"{question}\"\n",
        "\n",
        "expert_templates = {\n",
        "    \"physics\": physics_template,\n",
        "    \"math\": math_template,\n",
        "    \"history\": history_template,\n",
        "    \"computerscience\": computerscience_template,\n",
        "    \"default\": default_template\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77c46ddf",
      "metadata": {
        "height": 30,
        "id": "77c46ddf"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
        "from langchain_core.runnables import RunnableBranch, RunnableParallel\n",
        "from operator import itemgetter\n",
        "\n",
        "experts = {}\n",
        "for key, template in expert_templates.items():\n",
        "  prompt = ChatPromptTemplate.from_template(template)\n",
        "  experts[key] = prompt | llm | parser\n",
        "\n",
        "classifier_prompt = ChatPromptTemplate.from_messages([\n",
        "    # system\n",
        "    SystemMessagePromptTemplate.from_template(\"\"\"\n",
        "      Classify the question into one of the following topics:\n",
        "      - math: problems related to algebra, calculus, statistics, equations, and general mathematics.\n",
        "      - physics: topics in mechanics, electromagnetism, quantum physics, thermodynamics, etc.\n",
        "      - history: historical events, time periods, historical figures, and related context.\n",
        "      - computerscience: programming, algorithms, data structures, complexity, and general CS topics.\n",
        "      - default: any question that does not fit the above categories.\n",
        "      Only respond with one keyword: {keywords}.\"\"\"),\n",
        "    # human\n",
        "    HumanMessagePromptTemplate.from_template(\"Question: {question}\")\n",
        "])\n",
        "\n",
        "partial_prompt = classifier_prompt.partial(keywords=list(experts.keys()))\n",
        "\n",
        "classifier_chain = partial_prompt | llm | parser\n",
        "\n",
        "router_branch = RunnableBranch(\n",
        "    (lambda x: \"math\" in x[\"topic\"], experts[\"math\"]),\n",
        "    (lambda x: \"physics\" in x[\"topic\"], experts[\"physics\"]),\n",
        "    (lambda x: \"history\" in x[\"topic\"], experts[\"history\"]),\n",
        "    (lambda x: \"computerscience\" in x[\"topic\"], experts[\"computerscience\"]),\n",
        "    experts[\"default\"]\n",
        ")\n",
        "\n",
        "full_router_chain = RunnableParallel(\n",
        "    {\"topic\": classifier_chain,\n",
        "     \"question\": itemgetter(\"question\")}\n",
        "    ).assign(answer=router_branch)\n",
        "\n",
        "def route_question(question: str) -> str:\n",
        "    return full_router_chain.invoke({\"question\": question})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PMXR5JSoRW3W",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMXR5JSoRW3W",
        "outputId": "1a6c482d-ad0c-4ed6-bac0-2b44602712f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "====================================================================================================\n",
            "Question: Who are you?\n",
            "Topic: default\n",
            "Answer: I'm an artificial intelligence model known as Llama. Llama stands for \"Large Language Model Meta AI.\"\n",
            "====================================================================================================\n",
            "Question: Solve square(x) = 4\n",
            "Topic: math\n",
            "Answer: To solve the equation square(x) = 4, let's break it down into its component parts.\n",
            "\n",
            "The equation square(x) = 4 can be rewritten as x^2 = 4, since \"square(x)\" means x squared.\n",
            "\n",
            "Now, to solve for x, we need to find the values of x that make the equation true. \n",
            "\n",
            "To do this, we can take the square root of both sides of the equation:\n",
            "\n",
            "x^2 = 4\n",
            "x = ±√4\n",
            "x = ±2\n",
            "\n",
            "So, the solutions to the equation are x = 2 and x = -2.\n",
            "\n",
            "Therefore, the final answer is x = 2 or x = -2.\n",
            "====================================================================================================\n",
            "Question: Explain langchain in short\n",
            "Topic: computerscience\n",
            "Answer: **LangChain: A Framework for Building AI-Powered Applications**\n",
            "\n",
            "LangChain is an open-source framework that enables developers to build applications powered by large language models (LLMs). It provides a modular and flexible architecture for integrating LLMs into various applications, allowing developers to focus on building features rather than infrastructure.\n",
            "\n",
            "**Key Features:**\n",
            "\n",
            "1. **Modular Architecture**: LangChain allows developers to break down complex applications into smaller, reusable components.\n",
            "2. **LLM Integration**: LangChain provides pre-built connectors for popular LLMs, making it easy to integrate these models into applications.\n",
            "3. **Chain-Based Architecture**: LangChain's chain-based architecture enables developers to create complex workflows by linking multiple LLMs and other components together.\n",
            "\n",
            "**Benefits:**\n",
            "\n",
            "1. **Rapid Prototyping**: LangChain enables developers to quickly build and test AI-powered applications.\n",
            "2. **Flexibility**: LangChain's modular architecture allows developers to easily modify and extend their applications.\n",
            "3. **Scalability**: LangChain is designed to handle large volumes of data and traffic, making it suitable for production-ready applications.\n",
            "\n",
            "**Use Cases:**\n",
            "\n",
            "1. **Chatbots**: LangChain can be used to build conversational interfaces powered by LLMs.\n",
            "2. **Text Analysis**: LangChain can be used to analyze large volumes of text data using LLMs.\n",
            "3. **Content Generation**: LangChain can be used to generate content, such as articles or social media posts, using LLMs.\n",
            "\n",
            "Overall, LangChain provides a powerful framework for building AI-powered applications, enabling developers to focus on building innovative features rather than infrastructure.\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    questions = [\n",
        "        \"Who are you?\",\n",
        "        \"Solve square(x) = 4\",\n",
        "        \"Explain langchain in short\"\n",
        "    ]\n",
        "\n",
        "    for q in questions:\n",
        "        print(\"=\"*100)\n",
        "        response = route_question(q)\n",
        "        print(f\"Question: {q}\")\n",
        "        print(f\"Topic: {response['topic']}\")\n",
        "        print(f\"Answer: {response['answer']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93ed78c6",
      "metadata": {
        "id": "93ed78c6"
      },
      "source": [
        "* * *\n",
        "# Summary of Your LangChain Learning Journey: Chains\n",
        "\n",
        "In this notebook, you've embarked on a comprehensive exploration of **Chains** in LangChain, a core component for building complex LLM-powered workflows. Here's a recap of the key concepts you've mastered:\n",
        "\n",
        "**1. LangChain Expression Language (LCEL):**\n",
        "\n",
        "*   You started with the foundation of chain-building: the **LangChain Expression Language (LCEL)**. You learned how to use the intuitive `|` (pipe) syntax to link components (prompts, models, output parsers) together, creating simple yet powerful chains. This composition of components using the `|` operator results in a `RunnableSequence` object, which is the cornerstone of creating more complex chains.\n",
        "\n",
        "**2. Sequential Chains:**\n",
        "\n",
        "*   You took the next step by building **sequential chains**, where the output of one chain becomes the input for the next. This allowed you to create multi-step workflows, such as generating a company name and then writing a description for it.\n",
        "\n",
        "**3. Parallel Chains:**\n",
        "\n",
        "*   You explored the power of parallel execution with `RunnableParallel`. You learned how to run multiple independent chains at once and merge their results into a single object. This technique is invaluable for tasks that require multiple pieces of information to be generated simultaneously from a single input.\n",
        "\n",
        "**4. Router Chains:**\n",
        "\n",
        "*   Finally, you delved into advanced chaining by implementing a **Router Chain**. Using `RunnableBranch`, you created an intelligent system that can classify an input question and dynamically route it to the appropriate \"expert\" (a specialized chain) for an answer.\n",
        "\n",
        "**Key Takeaways:**\n",
        "\n",
        "Your journey through this notebook has equipped you with the skills to:\n",
        "\n",
        "*   **Grasp** the syntax and power of the LangChain Expression Language (LCEL) for fluently creating chains.\n",
        "*   **Construct** complex workflows by combining chains sequentially and in parallel.\n",
        "*   **Implement** dynamic routing logic to create decision-making applications that choose the right execution path based on the input.\n",
        "*   **Confidently combine** various LangChain components to build sophisticated and intricate LLM applications.\n",
        "\n",
        "You are now well-prepared to architect and build more diverse and powerful applications with LangChain. Excellent work!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e69fe763",
      "metadata": {
        "id": "e69fe763"
      },
      "source": [
        "* * *\n",
        "# Key Commands and Imports to Remember\n",
        "\n",
        "### Python Libraries:\n",
        "- **`import os`**: Interacts with the operating system, mainly for accessing environment variables.\n",
        "- **`from dotenv import load_dotenv`**: Loads environment variables from a `.env` file to securely manage API credentials.\n",
        "- **`from operator import itemgetter`**: A helper function used to fetch specific items from an input dictionary, often used within chains.\n",
        "\n",
        "### LangChain Libraries:\n",
        "- **`from langchain.chat_models import init_chat_model`**: Easily initializes a chat model instance from a provider.\n",
        "- **`from langchain_core.prompts import ChatPromptTemplate`**: For creating and formatting prompt templates that can be used in a chain.\n",
        "- **`from langchain_core.output_parsers.string import StrOutputParser`**: A simple parser to convert the chat model's message output into a string.\n",
        "- **`from langchain_core.runnables import RunnableParallel, RunnableBranch`**: Core components for building advanced chains that execute in parallel or follow conditional logic.\n",
        "\n",
        "### Key LangChain Concepts and Syntax:\n",
        "- **`|` (pipe operator)**: The fundamental syntax of the LangChain Expression Language (LCEL). It's used to chain runnables together, passing the output of one component as the input to the next.\n",
        "- **`ChatPromptTemplate.from_template()`**: A convenient method to create a prompt template from a simple string.\n",
        "- **`prompt.partial()`**: A method to pre-fill some variables in a prompt template, which is useful for creating specialized prompts.\n",
        "- **`RunnableParallel()`**: A runnable that executes other runnables in parallel. It takes a dictionary where values are runnables and returns a dictionary with the results.\n",
        "- **`Runnable.assign()`**: A method to add or modify the output of a chain by running an additional runnable and adding its result to the output dictionary.\n",
        "- **`RunnableBranch()`**: A runnable used to create conditional logic within a chain, allowing you to route the flow of execution based on the input."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
